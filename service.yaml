apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: ollama-app
  annotations:
    run.googleapis.com/launch-stage: "BETA"  # Required for sidecars
spec:
  template:
    metadata:
      annotations:
        run.googleapis.com/cpu-throttling: "false"
        autoscaling.knative.dev/maxScale: "1"
        run.googleapis.com/enable-http2: "true"  # Helps with streaming responses
    spec:
      containerConcurrency: 1
      containers:
      # Main container (must expose only one port)
      - name: app
        image: gcr.io/tom-riddle-diary1/streamlit-tom-app:latest
        ports:
        - containerPort: 8501  # Only one container can expose ports
        env:
        - name: OLLAMA_HOST
          value: "localhost:11434"
        resources:
          limits:
            cpu: "1"
            memory: 2G

      # Sidecar container (no port exposure)
      - name: llmodel
        image: ollama/ollama:latest
        # Removed ports section since sidecar can't expose ports
        command: ["/bin/sh"]
        args: ["-c", "ollama serve & sleep 5 && ollama pull phi3 && wait"]
        resources:
          limits:
            cpu: "2"
            memory: 8G
        livenessProbe:
          exec:  # Changed from httpGet since port isn't exposed
            command:
              - ollama
              - list
          initialDelaySeconds: 30  # Give more time for model to load
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        volumeMounts:
        - name: vol
          mountPath: /root/.ollama
      
      volumes:
      - name: vol
        emptyDir: {}

  traffic:
  - percent: 100
    latestRevision: true